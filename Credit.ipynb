{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Credit = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Credit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "Credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      False\n",
       "V1        False\n",
       "V2        False\n",
       "V3        False\n",
       "V4        False\n",
       "V5        False\n",
       "V6        False\n",
       "V7        False\n",
       "V8        False\n",
       "V9        False\n",
       "V10       False\n",
       "V11       False\n",
       "V12       False\n",
       "V13       False\n",
       "V14       False\n",
       "V15       False\n",
       "V16       False\n",
       "V17       False\n",
       "V18       False\n",
       "V19       False\n",
       "V20       False\n",
       "V21       False\n",
       "V22       False\n",
       "V23       False\n",
       "V24       False\n",
       "V25       False\n",
       "V26       False\n",
       "V27       False\n",
       "V28       False\n",
       "Amount    False\n",
       "Class     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(Credit).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Credit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGCCAYAAAD38Fn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6ce8659e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "count_classes = pd.value_counts(Credit['Class'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud Class Histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFkCAYAAAAKf8APAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6ce7ff1c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Credit['V1'].hist(bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-16a0fb1495e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscatter_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscatter_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCredit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kde'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mG:\\Anaconda3\\lib\\site-packages\\pandas\\tools\\plotting.py\u001b[0m in \u001b[0;36mscatter_matrix\u001b[0;34m(frame, alpha, figsize, ax, grid, diagonal, marker, density_kwds, hist_kwds, range_padding, **kwds)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 ax.scatter(df[b][common], df[a][common],\n\u001b[0;32m--> 380\u001b[0;31m                            marker=marker, alpha=alpha, **kwds)\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboundaries_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mG:\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1816\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1817\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1818\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mG:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   3893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ymargin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3896\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mG:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36madd_collection\u001b[0;34m(self, collection, autolim)\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mautolim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_datalim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_datalim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_remove_method\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mG:\\Anaconda3\\lib\\site-packages\\matplotlib\\collections.py\u001b[0m in \u001b[0;36mget_datalim\u001b[0;34m(self, transData)\u001b[0m\n\u001b[1;32m    203\u001b[0m             result = mpath.get_path_collection_extents(\n\u001b[1;32m    204\u001b[0m                 \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transforms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 offsets, transOffset.frozen())\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transformed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mG:\\Anaconda3\\lib\\site-packages\\matplotlib\\path.py\u001b[0m in \u001b[0;36mget_path_collection_extents\u001b[0;34m(master_transform, paths, transforms, offsets, offset_transform)\u001b[0m\n\u001b[1;32m    990\u001b[0m     return Bbox.from_extents(*_path.get_path_collection_extents(\n\u001b[1;32m    991\u001b[0m         \u001b[0mmaster_transform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         offsets, offset_transform))\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mG:\\Anaconda3\\lib\\site-packages\\matplotlib\\path.py\u001b[0m in \u001b[0;36mvertices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvertices\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0mNx2\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vertices\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(Credit, alpha=0.2, figsize=(6, 6), diagonal='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of normal transactions:  0.5\n",
      "Percentage of fraud transactions:  0.5\n",
      "Total number of transactions in resampled data:  984\n"
     ]
    }
   ],
   "source": [
    "X = Credit.ix[:, Credit.columns != 'Class']  \n",
    "y = Credit.ix[:, Credit.columns == 'Class']\n",
    "\n",
    "# Number of data points in the minority class\n",
    "number_records_fraud = len(Credit[Credit.Class == 1])\n",
    "fraud_indices = np.array(Credit[Credit.Class == 1].index)\n",
    "\n",
    "# Picking the indices of the normal classes\n",
    "normal_indices = Credit[Credit.Class == 0].index\n",
    "\n",
    "# Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\n",
    "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# Appending the 2 indices\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "\n",
    "# Under sample dataset\n",
    "under_sample_data = Credit.iloc[under_sample_indices,:]\n",
    "\n",
    "X_undersample = under_sample_data.ix[:, under_sample_data.columns != 'Class']\n",
    "y_undersample = under_sample_data.ix[:, under_sample_data.columns == 'Class']\n",
    "\n",
    "# Showing ratio\n",
    "print(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\n",
    "print(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\n",
    "print(\"Total number of transactions in resampled data: \", len(under_sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541    406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623    472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920  4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108  6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329  7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "\n",
       "            V7        V8        V9  ...         V21       V22       V23  \\\n",
       "541  -2.537387  1.391657 -2.770089  ...    0.517232 -0.035049 -0.465211   \n",
       "623   0.325574 -0.067794 -0.270953  ...    0.661696  0.435477  1.375966   \n",
       "4920  0.562320 -0.399147 -0.238253  ...   -0.294166 -0.932391  0.172726   \n",
       "6108 -3.496197 -0.248778 -0.247768  ...    0.573574  0.176968 -0.436207   \n",
       "6329  1.713445 -0.496358 -1.282858  ...   -0.379068 -0.704181 -0.656805   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "541   0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "623  -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "4920 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "6108 -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "6329 -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire Dataset\n",
      "Number transactions train dataset:  213605\n",
      "Number transactions test dataset:  71202\n",
      "Total number of transactions:  284807\n",
      "\n",
      "Under-sampled Dataset\n",
      "Number transactions train dataset:  738\n",
      "Number transactions test dataset:  246\n",
      "Total number of transactions:  984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Whole dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(\"Entire Dataset\")\n",
    "print(\"Number transactions train dataset: \", len(X_train))\n",
    "print(\"Number transactions test dataset: \", len(X_test))\n",
    "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
    "\n",
    "# Undersampled dataset\n",
    "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample,\n",
    "                                                                                                    y_undersample, \n",
    "                                                                                                    test_size = 0.25, \n",
    "                                                                                                    random_state = 0)\n",
    "print(\"\")\n",
    "print(\"Under-sampled Dataset\")\n",
    "print(\"Number transactions train dataset: \", len(X_train_undersample))\n",
    "print(\"Number transactions test dataset: \", len(X_test_undersample))\n",
    "print(\"Total number of transactions: \", len(X_train_undersample)+len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cv_score(clf, x, y):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    i = 0\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        i += 1\n",
    "        clf.fit(x.iloc[train,:], y.iloc[train,:].values.ravel()) # fit\n",
    "        y_pred = clf.predict(x.iloc[test,:]) #predict\n",
    "        print(\"Recall Score:\", recall_score(y.iloc[test,:].values.ravel(), y_pred), \"for Fold \", i)\n",
    "        result += recall_score(y.iloc[test,:].values.ravel(), y_pred) # evaluate recall score on held-out data\n",
    "        \n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01\n",
      "Recall Score: 0.875 for Fold  1\n",
      "Recall Score: 0.802469135802 for Fold  2\n",
      "Recall Score: 0.904761904762 for Fold  3\n",
      "Recall Score: 0.910256410256 for Fold  4\n",
      "Recall Score: 0.901408450704 for Fold  5\n",
      "Average Recall Score: 0.878779180305\n",
      "---------------------------------------------------\n",
      "C =  0.1\n",
      "Recall Score: 0.875 for Fold  1\n",
      "Recall Score: 0.814814814815 for Fold  2\n",
      "Recall Score: 0.904761904762 for Fold  3\n",
      "Recall Score: 0.935897435897 for Fold  4\n",
      "Recall Score: 0.915492957746 for Fold  5\n",
      "Average Recall Score: 0.889193422644\n",
      "---------------------------------------------------\n",
      "C =  1\n",
      "Recall Score: 0.875 for Fold  1\n",
      "Recall Score: 0.814814814815 for Fold  2\n",
      "Recall Score: 0.920634920635 for Fold  3\n",
      "Recall Score: 0.935897435897 for Fold  4\n",
      "Recall Score: 0.915492957746 for Fold  5\n",
      "Average Recall Score: 0.892368025819\n",
      "---------------------------------------------------\n",
      "C =  10\n",
      "Recall Score: 0.875 for Fold  1\n",
      "Recall Score: 0.814814814815 for Fold  2\n",
      "Recall Score: 0.920634920635 for Fold  3\n",
      "Recall Score: 0.948717948718 for Fold  4\n",
      "Recall Score: 0.929577464789 for Fold  5\n",
      "Average Recall Score: 0.897749029791\n",
      "---------------------------------------------------\n",
      "C =  100\n",
      "Recall Score: 0.875 for Fold  1\n",
      "Recall Score: 0.814814814815 for Fold  2\n",
      "Recall Score: 0.920634920635 for Fold  3\n",
      "Recall Score: 0.948717948718 for Fold  4\n",
      "Recall Score: 0.915492957746 for Fold  5\n",
      "Average Recall Score: 0.894932128383\n",
      "---------------------------------------------------\n",
      "Best C parameter: 10 ,  Maximum Recall Score: 0.897749029791\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "max_score = 0\n",
    "C_max = 0\n",
    "\n",
    "for c in Cs:\n",
    "    print(\"C = \", c)\n",
    "    clf_c = LogisticRegression(C=c)\n",
    "    score_c = cv_score(clf_c, X_train_undersample, y_train_undersample)\n",
    "    print(\"Average Recall Score:\", score_c)\n",
    "    print(\"---------------------------------------------------\")\n",
    "    if score_c > max_score:\n",
    "        max_score = score_c\n",
    "        C_max = c\n",
    "        \n",
    "print(\"Best C parameter:\", C_max, \", \", \"Maximum Recall Score:\", max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01\n",
      "Gamma =  0.1\n",
      "Recall Score: 0.0 for Fold  1\n",
      "Recall Score: 0.0 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.4\n",
      "---------------------------------------------------\n",
      "C =  0.01\n",
      "Gamma =  0.01\n",
      "Recall Score: 0.0 for Fold  1\n",
      "Recall Score: 0.0 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.4\n",
      "---------------------------------------------------\n",
      "C =  0.01\n",
      "Gamma =  0.001\n",
      "Recall Score: 0.0 for Fold  1\n",
      "Recall Score: 0.0 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.4\n",
      "---------------------------------------------------\n",
      "C =  0.01\n",
      "Gamma =  0.0001\n",
      "Recall Score: 0.0 for Fold  1\n",
      "Recall Score: 0.0 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.4\n",
      "---------------------------------------------------\n",
      "C =  0.1\n",
      "Gamma =  0.1\n",
      "Recall Score: 0.0 for Fold  1\n",
      "Recall Score: 0.0 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.4\n",
      "---------------------------------------------------\n",
      "C =  0.1\n",
      "Gamma =  0.01\n",
      "Recall Score: 0.0 for Fold  1\n",
      "Recall Score: 0.0 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.4\n",
      "---------------------------------------------------\n",
      "C =  0.1\n",
      "Gamma =  0.001\n",
      "Recall Score: 0.0 for Fold  1\n",
      "Recall Score: 0.0 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.4\n",
      "---------------------------------------------------\n",
      "C =  0.1\n",
      "Gamma =  0.0001\n",
      "Recall Score: 0.0 for Fold  1\n",
      "Recall Score: 0.0 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.4\n",
      "---------------------------------------------------\n",
      "C =  1\n",
      "Gamma =  0.1\n",
      "Recall Score: 0.0375 for Fold  1\n",
      "Recall Score: 0.0246913580247 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0384615384615 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.420130579297\n",
      "---------------------------------------------------\n",
      "C =  1\n",
      "Gamma =  0.01\n",
      "Recall Score: 0.0875 for Fold  1\n",
      "Recall Score: 0.0740740740741 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0641025641026 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.445135327635\n",
      "---------------------------------------------------\n",
      "C =  1\n",
      "Gamma =  0.001\n",
      "Recall Score: 0.225 for Fold  1\n",
      "Recall Score: 0.172839506173 for Fold  2\n",
      "Recall Score: 0.920634920635 for Fold  3\n",
      "Recall Score: 0.205128205128 for Fold  4\n",
      "Recall Score: 0.352112676056 for Fold  5\n",
      "Average Recall Score: 0.375143061598\n",
      "---------------------------------------------------\n",
      "C =  1\n",
      "Gamma =  0.0001\n",
      "Recall Score: 0.4625 for Fold  1\n",
      "Recall Score: 0.37037037037 for Fold  2\n",
      "Recall Score: 0.47619047619 for Fold  3\n",
      "Recall Score: 0.410256410256 for Fold  4\n",
      "Recall Score: 0.492957746479 for Fold  5\n",
      "Average Recall Score: 0.442455000659\n",
      "---------------------------------------------------\n",
      "C =  10\n",
      "Gamma =  0.1\n",
      "Recall Score: 0.05 for Fold  1\n",
      "Recall Score: 0.0246913580247 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0384615384615 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.422630579297\n",
      "---------------------------------------------------\n",
      "C =  10\n",
      "Gamma =  0.01\n",
      "Recall Score: 0.1 for Fold  1\n",
      "Recall Score: 0.0740740740741 for Fold  2\n",
      "Recall Score: 0.984126984127 for Fold  3\n",
      "Recall Score: 0.0769230769231 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.447024827025\n",
      "---------------------------------------------------\n",
      "C =  10\n",
      "Gamma =  0.001\n",
      "Recall Score: 0.25 for Fold  1\n",
      "Recall Score: 0.197530864198 for Fold  2\n",
      "Recall Score: 0.920634920635 for Fold  3\n",
      "Recall Score: 0.205128205128 for Fold  4\n",
      "Recall Score: 0.380281690141 for Fold  5\n",
      "Average Recall Score: 0.39071513602\n",
      "---------------------------------------------------\n",
      "C =  10\n",
      "Gamma =  0.0001\n",
      "Recall Score: 0.5125 for Fold  1\n",
      "Recall Score: 0.432098765432 for Fold  2\n",
      "Recall Score: 0.460317460317 for Fold  3\n",
      "Recall Score: 0.423076923077 for Fold  4\n",
      "Recall Score: 0.549295774648 for Fold  5\n",
      "Average Recall Score: 0.475457784695\n",
      "---------------------------------------------------\n",
      "C =  100\n",
      "Gamma =  0.1\n",
      "Recall Score: 0.05 for Fold  1\n",
      "Recall Score: 0.0246913580247 for Fold  2\n",
      "Recall Score: 1.0 for Fold  3\n",
      "Recall Score: 0.0384615384615 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.422630579297\n",
      "---------------------------------------------------\n",
      "C =  100\n",
      "Gamma =  0.01\n",
      "Recall Score: 0.1 for Fold  1\n",
      "Recall Score: 0.0740740740741 for Fold  2\n",
      "Recall Score: 0.984126984127 for Fold  3\n",
      "Recall Score: 0.0769230769231 for Fold  4\n",
      "Recall Score: 1.0 for Fold  5\n",
      "Average Recall Score: 0.447024827025\n",
      "---------------------------------------------------\n",
      "C =  100\n",
      "Gamma =  0.001\n",
      "Recall Score: 0.25 for Fold  1\n",
      "Recall Score: 0.197530864198 for Fold  2\n",
      "Recall Score: 0.920634920635 for Fold  3\n",
      "Recall Score: 0.205128205128 for Fold  4\n",
      "Recall Score: 0.380281690141 for Fold  5\n",
      "Average Recall Score: 0.39071513602\n",
      "---------------------------------------------------\n",
      "C =  100\n",
      "Gamma =  0.0001\n",
      "Recall Score: 0.525 for Fold  1\n",
      "Recall Score: 0.432098765432 for Fold  2\n",
      "Recall Score: 0.460317460317 for Fold  3\n",
      "Recall Score: 0.423076923077 for Fold  4\n",
      "Recall Score: 0.549295774648 for Fold  5\n",
      "Average Recall Score: 0.477957784695\n",
      "---------------------------------------------------\n",
      "Best C parameter: 100 ,  Best Gamma parameter: 0.0001 Maximum Recall Score: 0.477957784695\n"
     ]
    }
   ],
   "source": [
    "#SVM with RBF\n",
    "from sklearn import svm\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "Gammas = [0.1, 0.01, 0.001, 0.0001]\n",
    "max_score = 0\n",
    "C_max = 0\n",
    "\n",
    "for c in Cs:\n",
    "    for g in Gammas:\n",
    "        print(\"C = \", c)\n",
    "        print(\"Gamma = \", g)\n",
    "        clf = svm.SVC(C=c, gamma=g)\n",
    "        score_c_g = cv_score(clf, X_train_undersample, y_train_undersample)\n",
    "        print(\"Average Recall Score:\", score_c_g)\n",
    "        if score_c > max_score:\n",
    "            max_score = score_c_g\n",
    "            C_max = c\n",
    "            G_max = g\n",
    "        print(\"---------------------------------------------------\")\n",
    "        \n",
    "        \n",
    "print(\"Best C parameter:\", C_max, \", \", \"Best Gamma parameter:\", G_max, \"Maximum Recall Score:\", max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01\n",
      "Recall Score: 0.825 for Fold  1\n",
      "Recall Score: 0.777777777778 for Fold  2\n",
      "Recall Score: 0.793650793651 for Fold  3\n",
      "Recall Score: 0.871794871795 for Fold  4\n",
      "Recall Score: 0.802816901408 for Fold  5\n",
      "Average Recall Score: 0.814208068926\n",
      "---------------------------------------------------\n",
      "C =  0.1\n",
      "Recall Score: 0.825 for Fold  1\n",
      "Recall Score: 0.79012345679 for Fold  2\n",
      "Recall Score: 0.793650793651 for Fold  3\n",
      "Recall Score: 0.846153846154 for Fold  4\n",
      "Recall Score: 0.802816901408 for Fold  5\n",
      "Average Recall Score: 0.811548999601\n",
      "---------------------------------------------------\n",
      "C =  1\n",
      "Recall Score: 0.825 for Fold  1\n",
      "Recall Score: 0.777777777778 for Fold  2\n",
      "Recall Score: 0.825396825397 for Fold  3\n",
      "Recall Score: 0.846153846154 for Fold  4\n",
      "Recall Score: 0.859154929577 for Fold  5\n",
      "Average Recall Score: 0.826696675781\n",
      "---------------------------------------------------\n",
      "C =  10\n",
      "Recall Score: 0.825 for Fold  1\n",
      "Recall Score: 0.777777777778 for Fold  2\n",
      "Recall Score: 0.793650793651 for Fold  3\n",
      "Recall Score: 0.884615384615 for Fold  4\n",
      "Recall Score: 0.802816901408 for Fold  5\n",
      "Average Recall Score: 0.81677217149\n",
      "---------------------------------------------------\n",
      "C =  100\n",
      "Recall Score: 0.825 for Fold  1\n",
      "Recall Score: 0.777777777778 for Fold  2\n",
      "Recall Score: 0.84126984127 for Fold  3\n",
      "Recall Score: 0.858974358974 for Fold  4\n",
      "Recall Score: 0.802816901408 for Fold  5\n",
      "Average Recall Score: 0.821167775886\n",
      "---------------------------------------------------\n",
      "Best C parameter: 1 ,  Maximum Recall Score: 0.826696675781\n"
     ]
    }
   ],
   "source": [
    "#SVM with Linear\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "max_score = 0\n",
    "C_max = 0\n",
    "\n",
    "for c in Cs:\n",
    "        print(\"C = \", c)\n",
    "        clf = svm.SVC(C=c, kernel=\"linear\")\n",
    "        score_c = cv_score(clf, X_train_undersample, y_train_undersample)\n",
    "        print(\"Average Recall Score:\", score_c)\n",
    "        if score_c > max_score:\n",
    "            max_score = score_c\n",
    "            C_max = c\n",
    "        print(\"---------------------------------------------------\")\n",
    "        \n",
    "        \n",
    "print(\"Best C parameter:\", C_max, \", \", \"Maximum Recall Score:\", max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf = GridSearchCV(clf, parameters, cv=5, scoring=\"recall\")\n",
    "clf.fit(X_train_undersample.values, y_train_undersample.values.ravel())\n",
    "clf.best_params_, clf.best_score_, clf.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
